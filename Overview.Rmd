---
title: "Overview"
output: pdf_document
---

# 1. Distribution of sensory attributes

## Histogram

Let import the dataset, do a summary of it and identify quantitative variables (sensory attributes); we're gonna work only on this variables for moment.

```{r}
experts <- read.table(file="data/perfumes_qda_experts.csv",header=TRUE, sep=",",dec=".",quote="\"")
summary(experts)
```
The empirical distribution of a variable is the set of values (or modalities) taken by this variable, and their associated numbers. However, the variables being continuous, it is very rare to have the same value twice for two different individuals.

We therefore choose to make a grouping in classes.

The first point is to represent one variable. Choose it and plot its histogram.

```{r}
hist(experts$Spicy, main="Histogram of Spicy")
```

Here, a lot of information is available to us. The first one is an idea of the representation of the scores given by the judges to the attribute. We that a lot of notes are between 0 and 1. The rest is more homogeneous. As explain previously, this distribution is cut in classes. The cut is set by the argument `breaks`. By default, it is set with the _Sturges_ method, which is the most recommended in the most of the cases. If you specify manually this number,  make sure the number is not too high or not too low.

```{r}
hist(experts$Spicy, main="Histogram of Spicy", breaks=50)
```

We notice however that this histogram represents the frequencies of observations on the ordinate, or more precisely the number of observations of each class. It is the argument `freq = True` that gives us this representation. But you sometimes histograms are plot using Frequency density, the frequency per unit for the data in each class. It is calculated by dividing the frequency by the class width. We change the argument `probability` to `probability = TRUE` to have this representation.

```{r}
hist(experts$Spicy, main="Histogram of Spicy", breaks=50, probability=TRUE)
```

## Density

This notion of density is introduce here, it allows to restrict the frequencies of the classes between 0 and 1. Plot the density for one sensory attributes with the `density()` function of R.  

```{r}
d <- density(experts$Spicy) 
plot(d, main = "Density of Spicy") 
```

The histogram of frenquency density can be superposed to the curve. First, plot the histogram for one sensory attribute and add the line of the density.

```{r}
hist(experts$Vanilla, probability = TRUE)
lines(density(experts$Vanilla), col="red")
```

We can also compare two estimate density of two different variables. Create a graph with the lines of the density of two sensory attributes.

```{r}
plot(density(experts$Vanilla), col="blue", main="Vanilla and Floral density")
lines(density(experts$Floral), col="red")

legend(10, 0.2, legend=c("Vanilla", "Floral"),col=c("blue", "red"), lty=1:2, cex=0.8)
```

*Functions used : hist(), plot(), lines(), legend(), density()*

## Position indicator

Now that we have an idea of the variable density, we can introduce the notion of position indicator. We now want to know which notes "cut" the population into two groups of equal size. The median is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as "the middle" value. To generalize, we have the notion of quantile, which are cut points dividing the observations in a sample in the same way. 

We want to calculate the mean, the standard deviation, the first quantile and the third quantile for each sensory attributes in the data set `experts`. Do it and save them in a data frame. 

```{r}
dispersion <- data.frame("mean"=double(), "sd"=double(), "median"=double(), "q1"=double(), "q3"=double())

for (a in 5:16){
  me <- mean(experts[,a])
  sd <- sqrt(var(experts[,a]))
  med <- quantile(experts[,a], 0.5)
  q1 <- quantile(experts[,a], 0.25)
  q3 <- quantile(experts[,a], 0.75)
  dispersion <- rbind(dispersion, c(me, sd, med, q1, q3))
}

colnames(dispersion) <- c("mean", "sd", "median", "q1", "q3")
rownames(dispersion) <- colnames(experts[,5:16])
head(dispersion)
```

These indicators can be visualized, plot the box-plot of each sensory attributes. Do it on three attributes and add the line corresponding to the mean. 

```{r}
# To get 3 graphs on a single window :
par(mfrow=c(1,3))

for (a in 5:7){
  boxplot(experts[,a], xlab=paste0("Boxplot of ", colnames(experts[a])))
  
  # Mean
  text(0.75,mean(experts[,a])+0.25, "mean", pos=2)
  abline(h=mean(experts[,a]))
  
  # Q1
  text(0.75,quantile(experts[,a], probs = 0.25)+0.25, "q1", pos=2)
  abline(h=quantile(experts[,a], probs = 0.25))
  
  # Q3
  text(0.75,quantile(experts[,a], probs = 0.75)+0.25, "q3", pos=2)
  abline(h=quantile(experts[,a], probs = 0.75))
  
  # Median
  text(0.75,quantile(experts[,a], probs = 0.5)+0.25, "Median", pos=2)
  abline(h=quantile(experts[,a], probs = 0.5))
  
}

```


Let's illustrate these indicators in complementary of the density. For example, the median is a quantile associate to the order 0.5 :

```{r}
d<-density(experts$Vanilla)

# Plot the line
plot(d, main="Vanilla distribution and median")
p50 <- which.max(cumsum(d$y/sum(d$y)) >= 0.50)

# Plot the shading
polygon(c(-5, d$x[1:p50], d$x[p50]), c(0, d$y[1:p50], 0), col = 'lightblue')
```

Do the same with the first and third quantile. 

```{r}
d<-density(experts$Vanilla)

# Plot the line
plot(d, main="Vanilla Distribution and quartile")

# Get indexes of quantiles 0.25 and 0.75
q25 <- which.max(cumsum(d$y/sum(d$y)) >= 0.25)
q75 <- which.max(cumsum(d$y/sum(d$y)) >= 0.75)

# Plot the first quantile
polygon(x=c(-5, d$x[1:q25], d$x[q25]), y=c(0, d$y[1:q25], 0), col = 'lightblue')

# Plot the third quantile
polygon(x=c(d$x[q75], d$x[d$x > d$x[q75]], 15),y=c(0, d$y[d$x > d$x[q75]], 0),col = "lightblue") 
```

Finally, plot the density again and add the mean and 2.5 and 97.5 quantile.

```{r}
d<-density(experts$Vanilla)

# Plot the line
plot(d, main="Vanilla Distribution and quantiles")
q025 <- which.max(cumsum(d$y/sum(d$y)) >= 0.025)
q975 <- which.max(cumsum(d$y/sum(d$y)) >= 0.975)

# Plot the shading
polygon(c(-5, d$x[1:q025], d$x[q025]), c(0, d$y[1:q025], 0), col = 'lightblue')
polygon(c(d$x[q975], d$x[d$x > d$x[q975]], 15),c(0, d$y[d$x > d$x[q975]], 0),col = "lightblue")

# Plot the vline for mean
abline(v=mean(experts$Vanilla))
text(mean(experts$Vanilla),0.2, "mean", pos=2)

# Plot the vline for Q97.5
abline(v=d$x[q975])
text(d$x[q975],0.2, "Q97.5", pos=2)

# Plot the vline for Q0.25
abline(v=d$x[q025])
text(d$x[q025],0.2, "Q0.25", pos=2)
```

*Functions used : data.frame(), which.max(), polygon(), abline(), par()*

# 2. Product effect

The sensory attributes are collected for different products, let's take account of this point. Remember the data set, `Product`, `Session`, `Panelist` and `Rank` must be categorical, do the transformation. 

```{r}
experts$Product <- as.factor(experts$Product)
experts$Panelist <- as.factor(experts$Panelist)
experts$Session <- as.factor(experts$Session)
experts$Rank <- as.factor(experts$Rank)
```

The point of interest in sensory analysis is the product effect on each sensory attributes. To begin, plot the density for one sensory attribute and for three product. To do it, you must to use `ggplot2` and `dplyr` libraries.

```{r}
library(ggplot2)
library(dplyr)

experts %>%  
  # Select 3 products and 1 sensory attribute
  select(c(Product, Floral)) %>% 
  filter(Product == "J'adore ET" | Product == "Angel" | Product == "Chanel N5" ) %>%
  # Add the mean's column
  group_by(Product) %>% 
  mutate(mu=mean(Floral)) %>% 
  # Graph
  ggplot() + aes(x=Floral, fill=Product) + geom_density(alpha=0.4) + geom_vline(aes(xintercept=mu, color=Product),linetype="dashed") + labs(title="Density of Spicy according three products")
```

Each sensory attributes has different dispersion depending on the product youâ€™re focusing on, it's the product effect.

The next part focus on the box-plots of the same sensory attribute. Using the same libraries, build three box-plot for three products.

```{r}
experts %>%  
  # Select 3 products and 1 sensory attribute
  select(c(Product, Floral)) %>% 
  filter(Product == "Coco Mademoiselle" | Product == "Angel" | Product == "Chanel N5" ) %>%
  
  # Graph
  ggplot() + aes(y=Floral, x= Product, fill=Product) + geom_boxplot() + labs(title="Boxplot of Floral according three products")
```
*Functions used : select(), group_by(), filter(), mutate(), ggplot(), geom_boxplot()*

# 3. Differences between products 

To have a better understanding of this differences between products, we use the precedent box-plots, where we add a segment between each means. Choose three products and one sensory attributes and run this code :

```{r}
experts %>%  
  # Select 3 products and 1 sensory attribute
  select(c(Product, Floral)) %>% 
  filter(Product == "J'adore ET" | Product == "Angel" | Product == "Chanel N5" ) %>% 

  ggplot()+aes(y=Floral, x= Product, fill=Product) + geom_boxplot() + 
    stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
    stat_summary(fun=mean, geom="point")
```

These segments are equivalent to a `distance` between all the product, in the sensory attribute point of view. Try to have these visualization for four sensory attributes and for each, three products. So you need to plot four graphs, for this use the `gridExtra` library. With the `grid.arrange` function, you can arrange all your plots like you want. 

```{r}
library(gridExtra)

# Select three sensory attributes and three products 
df <- experts %>%  
  select(c(Product, Floral, Citrus, Spicy, Heady)) %>% 
  filter(Product == "J'adore ET" | Product == "Angel" | Product == "Chanel N5" )

# First sensory attribute
a1 <- ggplot(df)+aes(y=Floral, x= Product, color=Product)+geom_boxplot() + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  # Delete the x-axis:
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# Second sensory attribute
a2 <- ggplot(df)+aes(y=Spicy, x= Product, color=Product)+geom_boxplot() + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# Third sensory attribute
a3 <- ggplot(df)+aes(y=Citrus, x= Product, color=Product)+geom_boxplot() + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# Fourth sensory attribute
a4 <- ggplot(df)+aes(y=Heady, x= Product, color=Product)+geom_boxplot() + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

grid.arrange(a1, a2, a3,a4, ncol=2, nrow = 2)
```

Now, do exactly the same without plotting the box-plots:

```{r}
a1 <- ggplot(df)+aes(y=Floral, x= Product, color=Product)+ 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a2 <- ggplot(df)+aes(y=Citrus, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a3 <- ggplot(df)+aes(y=Spicy, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a4 <- ggplot(df)+aes(y=Heady, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

grid.arrange(a1, a2, a3, a4, ncol=2, nrow = 2)
```

To finish, we want to plot same graphs but without the variance. This very important step makes it possible to compare individuals with each other in relation to a reference value which is the one in 0. Moreover, by dividing by the standard deviation, each individual has the same weight which is 1.

To do, you need to divide values by the standard deviation. Next, plot the same graphs :

```{r}
df$Floral <- df$Floral/sd(df$Floral)
df$Citrus <- df$Citrus/sd(df$Citrus)
df$Spicy <- df$Spicy/sd(df$Spicy)
df$Heady <- df$Heady/sd(df$Heady)

a1 <- ggplot(df)+aes(y=Floral, x= Product, color=Product)+ 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a2 <- ggplot(df)+aes(y=Citrus, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a3 <- ggplot(df)+aes(y=Spicy, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

a4 <- ggplot(df)+aes(y=Heady, x= Product, color=Product) + 
  stat_summary(fun=mean, geom="line", aes(group=1), color="black") + 
  stat_summary(fun=mean, geom="point")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

grid.arrange(a1, a2, a3, a4, ncol=2, nrow = 2)
```


We have finally 4 univariate analysis of the mean differences between all the products for each attributes. For example, _Chanel N5_ and _Angel_ are closer than _J'adore ET_ in Spicy perception. They have a shorter "distance" between them. 

We can summary these graphics in four _4x4_ matrix with the distance mean-mean for each product. To get it, start to get the data frame of means of three sensory attributes for three products. 

```{r}
means <- df %>% group_by(Product) %>% summarise(
  mean_Spicy=mean(Spicy),
  mean_Citrus=mean(Citrus),
  mean_Floral=mean(Floral)
)
means
```

*Functions used :  stat_summary()*

# 4. Notion of metric

Next, calculate the distances-matrix for each sensory attributes.

```{r}
spicy.matrix <- as.matrix(dist(means$mean_Spicy))
citrus.matrix <- as.matrix(dist(means$mean_Citrus))
floral.matrix <- as.matrix(dist(means$mean_Floral))
```

Try to combine them in order to visualize simultaneously.

```{r}
a1 <- ggplot(means)+aes(x = mean_Spicy, y=mean_Citrus, color=Product)+geom_path(aes(group=1),color="black")+geom_point()
a2 <- ggplot(means)+aes(x = mean_Spicy, y=mean_Floral, color=Product)+geom_path(aes(group=1),color="black")+geom_point()
a3 <- ggplot(means)+aes(x = mean_Citrus, y=mean_Floral, color=Product)+geom_path(aes(group=1),color="black")+geom_point()

grid.arrange(a1, a2, a3, ncol=2, nrow = 2)
```

A negative slope between two sensory attributes can be traduce like a negative linear relation, and conversely.This is the notion of correlation, it's a standardized form of covariance. You can observe the sign of values and compare them with the previous graphs.

```{r}
means.variables <- data.frame(means, row.names = 1)
cov.att <- cov(means.variables)
```

We can save information about these attributes without products and the dispersion can be traduce with distances between us. 

```{r}
dist.prod <- as.matrix(dist(means.variables))
```

*Functions used : as.matrix(), geom_path(), geom_point(), cov(), dist()*

# 5. Structure 

With the data frame of means built just before, we get the two matrix of distances between products `dist.prod` and the matrix of co-variance attributes `cov.att`.  

`heatmap()` function is used to visualize values of a matrix in colors, columns and rows are ordered before and that's why we can already find somes structures. Do it on the both matrix and try to find structures.

```{r}
heatmap(cov.att)
heatmap(dist.prod)
```
*Functions used : heatmap()*

# 6. Inertia 

With these formulas, we can calculate inertia on both matrix. If you scale them, the inertia must be equal to the dimension of them (here 3). 

```{r}
Products_sc_Mat <- as.matrix(dist(scale(dist.prod))^2)
sum(Products_sc_Mat)/(2*dim(Products_sc_Mat)[1]*(dim(Products_sc_Mat)[1]-1))

Att_sc_Mat <- as.matrix(dist(scale(cov.att))^2)
sum(Att_sc_Mat)/(2*dim(Att_sc_Mat)[1]*(dim(Att_sc_Mat)[1]-1))
```

We can decompose inertia, as we can decompose our distance matrix in block regarding the heatmap. With the same methode, calculate the inertia of one group and for others : 

```{r}
floral_citrus <- as.data.frame(cov.att) %>% select(mean_Citrus, mean_Floral)
floral_citrus <- floral_citrus[-1,] 

Att_floral_citrus_sc_Mat <- as.matrix(dist(scale(floral_citrus))^2)
sum(Att_floral_citrus_sc_Mat)/(2*dim(Att_floral_citrus_sc_Mat)[1]*(dim(Att_floral_citrus_sc_Mat)[1]-1))

spicy <- as.data.frame(cov.att)[1,1]
# Prendre plus grande matrice
```
>>>>>>> Prendre plus grande matrice pr avoir au moins 2 groupes != de 1 ind/var

*Functions used : sum(), dim(), scale()*

# 7. PCA

## FactoMineR

Using the `PCA()` function from FactoMineR, do the method on the matrix of means of attributes and print the coordinates of individuals and variables.

```{r}
library(FactoMineR)
res<-PCA(scale(means.variables), graph = FALSE, scale.unit = F)
res$ind$coord
res$var$coord
```

## Decomposition with svd() 

Now, we gonna do the PCA on the same matrix but manually and using the `svd()` function that does the decomposition of the matrix.

```{r}
svd <- svd(scale(means.variables))
diag <- diag(svd$d)

#Verification
svd$u%*%diag%*%t(svd$v)
scale(as.matrix(means.variables))[1:3,1:3]

#Individuals coordinates
scale(means.variables)%*%svd$v
#Variables coordinates
t(scale(means.variables))%*%svd$u/sqrt(3)

#Comparate with PCA()
res$ind$coord
res$var$coord
```

## Using Nipals algorithm

```{r}
NIPALS <- function(X){
  X = as.matrix(X)
  N = nrow(X)
  M = ncol(X)
  
  D = diag(1/N, N)
  Xini = X
  qrX=qr(X)
  rang = qrX$rank
  vec=matrix(0,nrow=M,ncol=rang) 
  t=X[,1]
  i=1
  
  p=t(X)%*%t%*%(1/(t(t)%*%t))
  p=p/as.numeric(sqrt(t(p)%*%p))
  print(rang)
  while (i<rang+1) {
    norm=1
    while(norm>0.000001){
      t=(X%*%p)%*%(1/(t(p)%*%p))
      p2=t(X)%*%t%*%(1/(t(t)%*%t))
      p2=p2/as.numeric(sqrt(t(p2)%*%p2))
      diff=p2-p
      norm=t(diff)%*%diff
      p=p2
      print(p)
      print(i)
    }
    vec[,i]=p
    X=X-(t%*%t(p))
    i=i+1
  }
  return(vec)
}

NIPALS(means.variables)
svd(means.variables)$v
```
# 7. Supplementary informations 

Now, we know how is performed the PCA and how we get the coordinates of individuals or variables. To a better understanding of results, including supplementary information is very important and technically not complicated.

## Supplementary variables 
 
As PCA only uses continuous variables in the calculation of the distances between individuals, categorical variables can only be considered as supplementary. For continuous variables, determining whether they are illustrative or not is arbitrary, and depends on the point of view adopted. Often, continuous variables are considered as supplementary if they are from a different nature. 

>>>>>>> exemple ajout var supp 

We can use supplementary individuals to a better understanding of structures. For example, adding supplementary individuals that you already know characteristics is appropriate to compare new products. This requires knowledge and expertise that is external and specific to the study context.

>>>>>>> exemple ajout ind supp 
